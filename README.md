# Ollama Chat Interface

A web-based chat interface for interacting with various Ollama models using Streamlit.

## Features
- Chat with different Ollama models
- Switch between available models
- Clean and intuitive user interface
- History of conversations

## Requirements
- Python 3.8+
- Ollama installed and running locally
- Required Python packages (see requirements.txt)

## Setup
1. Clone this repository
2. Install requirements:
   ```
   pip install -r requirements.txt
   ```
3. Make sure Ollama is running on your system
4. Run the application:
   ```
   streamlit run app.py
   ```

## Usage
1. Select an Ollama model from the dropdown
2. Type your message in the input field
3. Press Enter or click Send to chat with the model

## Note
Ensure that Ollama is properly installed and running on your system before using this interface.